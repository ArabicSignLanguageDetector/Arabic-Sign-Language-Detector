<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
  <title>ğŸ¤Ÿ Arabic Sign Language Detector â€“ ÙƒØ§Ø´Ù Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</title>
  <style>
    body {
      text-align: center;
      background-color: #f9f9f9;
      font-family: sans-serif;
    }
    h1 {
      color: #333;
      margin-top: 30px;
    }
    video {
      width: 90%;
      border: 4px solid #555;
      border-radius: 12px;
      margin-top: 20px;
    }
    canvas {
      display: none;
    }
    button {
      font-size: 18px;
      padding: 8px 15px;
      margin: 5px;
      border: none;
      border-radius: 8px;
      background-color: #007BFF;
      color: white;
      cursor: pointer;
    }
    button:hover {
      background-color: #0056b3;
    }
    #language-buttons {
      margin-top: 15px;
    }
  </style>
</head>
<body>
  <h1 id="title">ğŸ¤Ÿ Arabic Sign Language Detector</h1>
  <div id="language-buttons">
    <button onclick="setLanguage('en')">ğŸ‡ºğŸ‡¸ English</button>
    <button onclick="setLanguage('ar')">ğŸ‡¸ğŸ‡¦ Ø¹Ø±Ø¨ÙŠ</button>
    <button id="activateBtn">Activate Voice</button>
  </div>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas" width="224" height="224"></canvas>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    let currentLang = 'en';
    let speechEnabled = false;
    let englishVoice = null;
    let arabicVoice = null;
    let lastSpoken = "";

    // âœ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    const isMobile = /iPhone|iPad|Android/i.test(navigator.userAgent);
    const facingMode = isMobile ? { exact: "environment" } : "user";

    navigator.mediaDevices.getUserMedia({ video: { facingMode: facingMode }, audio: false })
      .then(stream => {
        video.srcObject = stream;
      })
      .catch(err => {
        alert("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§");
        console.error(err);
      });

    // âœ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ØºØ©
    function setLanguage(lang) {
      currentLang = lang;
      document.documentElement.lang = lang;
      document.documentElement.dir = lang === "ar" ? "rtl" : "ltr";
      document.getElementById("title").innerText =
        lang === "ar" ? "ğŸ¤Ÿ ÙƒØ§Ø´Ù Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" : "ğŸ¤Ÿ Arabic Sign Language Detector";
      document.getElementById("activateBtn").innerText =
        lang === "ar" ? "ØªÙØ¹ÙŠÙ„ Ø§Ù„ØµÙˆØª" : "Activate Voice";
    }

    // âœ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ØµÙˆØª
    function activateSpeech() {
      const voices = window.speechSynthesis.getVoices();
      if (!voices.length) return;

      englishVoice = voices.find(voice => voice.lang.startsWith("en")) || voices[0];
      arabicVoice = voices.find(voice => voice.lang.startsWith("ar")) || voices[0];

      const msg = new SpeechSynthesisUtterance(
        currentLang === "ar" ? "ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ØµÙˆØª" : "Voice activated."
      );
      msg.lang = currentLang === "ar" ? "ar-SA" : "en-US";
      msg.voice = currentLang === "ar" ? arabicVoice : englishVoice;
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(msg);
      speechEnabled = true;
    }

    document.getElementById("activateBtn").addEventListener("click", () => {
      if (!window.speechSynthesis.getVoices().length) {
        window.speechSynthesis.onvoiceschanged = activateSpeech;
      } else {
        activateSpeech();
      }
    }, { once: true });

    function speakPrediction(label) {
      if (!speechEnabled || label === lastSpoken) return;
      lastSpoken = label;

      const utterance = new SpeechSynthesisUtterance(label);
      utterance.lang = currentLang === "ar" ? "ar-SA" : "en-US";
      utterance.voice = currentLang === "ar" ? arabicVoice : englishVoice;
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(utterance);
    }

    // âœ… Ø¥Ø±Ø³Ø§Ù„ Ù„Ù‚Ø·Ø§Øª Ù…ØªÙƒØ±Ø±Ø© Ù„Ù„Ø³ÙŠØ±ÙØ± ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚Ø¹
    setInterval(() => {
      if (video.readyState !== 4) return;

      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = canvas.toDataURL('image/jpeg');

      fetch('/predict', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image: imageData })
      })
      .then(res => res.json())
      .then(data => {
        const label = data.label;
        speakPrediction(label);
      })
      .catch(err => console.error('Prediction error:', err));
    }, 1000);
  </script>
</body>
</html>
